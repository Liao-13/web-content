---
id: release_notes.md
summary: Milvus Release Notes
---
# Release Notes

Find out whatâ€™s new in Milvus! This page summarizes new features, improvements, known issues, and bug fixes in each release. You can find the release notes for each released version after v2.4.0 in this section. We suggest that you regularly visit this page to learn about updates.

## v2.4.0-rc.1
Release date: March 14, 2024

| Milvus version | Python SDK version | Java SDK version | Go SDK version | Node.js SDK version |
| -------------- | ------------------ | ---------------- | -------------- | ------------------- |
| 2.4.0          | 2.4.0              | 2.4.0            | 2.4.0          | 2.4.0               |

This latest release of Milvus introduces several new features based on different scenarios. For instance, multi-vector and hybrid search support can better facilitate multi-modal scenarios. Moreover, support for sparse vectors helps to expand the scope of vector search, which is highly promising for keyword understanding and interpretability. To improve keyword retrieval capability, inverted index and fuzzy matching are also supported. For typical RAG application scenarios, Grouping search support for categorical aggregation is introduced to help document-level recall instead of chunk-level recall.

In terms of performance, Milvus 2.4.0-rc.1 fully supports NVIDIA's latest RAFT algorithm libraries, including bruteforce, CAGRA, and IVF for different scenarios. With GPU support, not only is the index building time significantly reduced, but also the QPS of vector searches, especially in batch search scenarios, is improved by tens to hundreds of times.

### New Features

#### GPU Indexing

We would like to express our sincere gratitude to the NVIDIA team for their invaluable contribution to CAGRA, a state-of-the-art (SoTA) GPU-based graph index that can be used online. 

Unlike previous GPU indices, CAGRA demonstrates overwhelming superiority even in small batch queries, an area where CPU indices traditionally excel. In addition, CAGRA's performance in large batch queries and index construction speed, domains where GPU indices already shine, is truly unparalleled.

CAGRA is an open-source project that aims to revolutionize graph indexing by leveraging the power of GPUs. It is an ideal choice for various applications that require fast and efficient graph processing.

You can create a GPU index using CARGA as follows:

```python
fields = [
    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True),
    FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION),
]
schema = CollectionSchema(fields=fields, enable_dynamic_field=True)
collection = Collection(name=COLLECTION_NAME, schema=schema)

index_params = {
    "metric_type": "L2",
    "index_type": "GPU_CAGRA",
    "params": {
        'intermediate_graph_degree': 64,
        'graph_degree': 32
    }
}

collection.create_index(
    "embeddings", index_params)
```

For details, read [GPU Index](gpu_index.md) for more.

#### Sparse Vector (Beta)

In this release, we are introducing a new type of vector field called sparse vector. Sparse vectors are different from their dense counterparts as they tend to have several magnitude higher number of dimensions with only a handful being non-zero. This feature offers better interpretability due to its term-based nature and can be more effective in certain domains. Learned sparse models such as SPLADEv2/BGE-M3 have proven to be very useful for common first-stage ranking tasks. The main use case for this new feature in Milvus is to allow efficient approximate semantic nearest neighbor search over sparse vectors generated by neural models such as SPLADEv2/BGE-M3 and statistics models such as the BM25 algorithm. Milvus now supports effective and high-performance storage, indexing, and searching (MIPS, Maximum Inner Product Search) of sparse vectors.

You can create a sparse vector field as follows:

```python
fields = [
        FieldSchema(name="pk", dtype=DataType.VARCHAR, is_primary=True,max_length=100),
        FieldSchema(name="embeddings", dtype=DataType.SPARSE_FLOAT_VECTOR),
    ]
schema = CollectionSchema(fields, "hello_sparse is the simplest demo to introduce sparse float vector usage")

hello_sparse = Collection("hello_sparse", schema, consistency_level="Strong")

index = {
    "index_type": "SPARSE_INVERTED_INDEX",
    "metric_type": "IP",
    "params":{
         "drop_ratio_build": 0.2,
    }
}
hello_sparse.create_index("embeddings", index)

hello_sparse.search(vectors_to_search, "embeddings", search_params, limit=3, output_fields=["pk","embeddings"])
```

For details, read [Sparse Vector](sparse_vector.md) for more.

#### Multi-Vector Search

With multi-vector support, users can now incorporate multiple vector fields within a single collection, enabling them to perform sophisticated, hybrid searches that leverage multiple perspectives of data. This feature is not just an enhancement; it is a cornerstone for applications that require multi-model data processing, multi-embedding models, and the integration of both dense and sparse vectors.

Specifically, with multi-vector support, users can

- Conduct more nuanced searches that consider multiple aspects of an entity, such as text, image, and audio data.
- Store multi-modal information and search from different perspectives to enhance the richness of recall.
- Customize search strategies by assigning weights to different data modalities, leading to more relevant and precise search results.
- Experiment with various embedding models to find the optimal combination for their specific use case.

To use this feature, you should

- Create multiple vector fields in the same collection. The vector field type can be (FLOAT_VECTOR, BINARY_VECTOR, FLOAT16_VECTOR, SPARSE_FLOAT_VECTOR), and there is an upper limit on the number of vector columns, which can be configured through parameters. 
- Create an index for each vector column and recommend specifying the index name when creating the index.
- Use the new hybrid_search (pymilvus for example) interface and specify the rank type for the search.

Currently, Milvus provides two rerank strategies: Reciprocal Rank Fusion (RRF) and Average Weighted Scoring.

- __Reciprocal Rank Fusion (RRF)__

    This strategy is used for combining the results from multiple search strategies or vector fields. It works on the principle that the relevance of an item is inversely related to its rank across different search results. By taking the reciprocal of the rank positions and summing them, RRF can effectively combine and rerank the results, giving higher priority to items that appear consistently across different searches.

- __Average Weighted Scoring__

    This strategy involves assigning different weights to the scores obtained from each vector field and then calculating the average. The weights allow you to prioritize certain vector fields over others based on their importance to the search context. The final score is a weighted average that takes into account the relevance of each vector field to the query, resulting in a balanced and customized ranking of search results.

You can conduct a hybrid search as follows:

```python
search_param1 = {
    "data": [[1.0, 1.0]],
    "anns_field": "films",
    "param": {"metric_type": "L2", "offset": 1},
    "limit": 2,
    "expr": "film_id > 0",
}

req1 = AnnSearchRequest(**search_param1)

search_param2 = {
    "data": [[2.0, 2.0]],
    "anns_field": "poster",
    "param": {"metric_type": "L2", "offset": 1},
    "limit": 2,
    "expr": "film_id > 0",
}

req2 = AnnSearchRequest(**search_param2)  
                      
res = collection.hybrid_search(
                        reqs=[req1, req2], 
                        rerank=RRFRanker(), 
                        limit=2)
                        
res = collection.hybrid_search(
                        reqs=[req1, req2], 
                        rerank=WeightedRanker(0.9, 0.1), 
                        limit=2)
```

For details, read [Multi-Vector Search](multi-vector-search.md) for more.

#### Inverted Index and Fuzzy Match

Milvus supports a variety of scalar data types, including several numeric types, string, array, and JSON. It also features SIMD acceleration for filtering operations. However, filtering operations on data types like strings and JSON can still encounter significant performance bottlenecks. For strings and numeric types, older versions of Milvus utilized memory-based inverted indexes and Marisa Trie indexes. These indexes, while functional, consumed a high amount of memory and did not offer sufficiently fast query performance.

In this release, a scalar inverted index based on Tantivy (Yes, Milvus is now part of the Rust community! A big thanks to the Tantivy team for their masterpiece) is available. This type of index applies to all numeric and string data types, and greatly improves the query performance against string fields by up to tens of times. 

You can create an inverted index for a scalar field as follows:

```python
fields = [
    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True),
    FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=200),
    FieldSchema(name='release_year', dtype=DataType.INT64),
    FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION),
]
schema = CollectionSchema(fields=fields, enable_dynamic_field=True)
collection = Collection(name=COLLECTION_NAME, schema=schema)

# create inverted index
collection.create_index(
    "release_year", {"index_type": "INVERTED"})
collection.create_index(
    "title", {"index_type": "INVERTED"})
```

For details, read [Index Scalar Fields](index-scalar-fields.md) for more.

In addition, this release also supports fuzzy matches in scalar filtering for string fields through prefixes, infixes and suffixes.

You can define a fuzzy match filter as follows:

```python
# prefix match
VARCHAR like "prefix%"

# infix match
VARCHAR like "%middle%"

# suffix match
VARCHAR like "%suffix"
VARCHAR like "_suffix"
```

#### Grouping Search

When using Milvus for searching, you can group your results by a specific field to avoid duplicate entries of the same field item. This can help you obtain a more diverse set of results for that particular field. 

For instance, if you have a collection of documents where each document has various passages, you can represent each passage with a vector embedding and associate it with a document. To retrieve relevant documents instead of individual passages, you can use the `group_by_field` parameter in the `search()` operation to group the results by the document ID. This will help you obtain the most relevant and unique documents rather than multiple passages from the same document.

Moreover, for RAG (Retrieval-Augmented Generation) application scenarios, Milvus supports categorical aggregation for grouping search to help improve document-level recall rather than chunk-level recall.

The following code demonstrates how to use grouping search:

```python
# Group search results
res = collection.search(
    vectors,
    "float_vector",
    search_params={
    "metric_type": "L2",
    "params": {"nprobe": 10},
    },
    limit=10, # Max. number of search results to return
    group_by_field="doc_id", # Group results by document ID
    output_fields=["doc_id", "passage_id"]
)
# Retrieve the values in the `doc_id` column
doc_ids = [result['entity']['doc_id'] for result in res[0]]
print(doc_ids)
```

For details, read [Single-Vector search](single-vector-search.md) for more.

#### FP16 and BFloat16 Vectors

Half-precision data types like FP16 and BFloat16 are commonly used in both hardware and software for machine learning or neural networks. In the previous versions of Milvus, only Float32 vectors were supported. However, with the release of version 2.4.0-rc.1, support for Float16/BFloat16 vectors has been added. Although Float16/BFloat16 may sacrifice some accuracy, it offers improved query efficiency and more efficient memory usage.

You can create a collection with a Float16/BFloat16 vector field as follows:

```python
bf16_vector = FieldSchema(name="bf16_vector", dtype=DataType.BFLOAT16_VECTOR, dim=dim)

fp16_vector = FieldScheam(name="fp16_vector",
dtype=DataType.Float16Vector, dim=dim)

schema = CollectionSchema(fields=[int64_field, bf16_vector, fp16_vector])
```

#### Upgraded Architecture

In this release, we have upgraded the architecture of Milvus. For details, refer to the [Architecture Overview](architecture_overview.md).

#### L0 Segment

In this release, L0 Segment, which is a new type of segment, is available. It only records deleted data. Milvus periodically splits the data in this segment into sealed segments through compaction, which relieves you from frequently flushing data after deletions. The introduction of L0 Segment can significantly reduce the number of small files on the object storage and greatly improve the stability and performance of deletion and upsert operations.

#### Refactored BulkInsert

We have overhauled the bulk insert logic, enabling seamless import of multiple files in a single request. Performance has been enhanced with faster speeds achieved through improved parallelism. You'll notice a stability boost, ensuring robust functionality with minimal interruptions for smoother operations. We've optimized various features, including fine-tuned rate limiting, error messaging, and more. Additionally, RESTful API support has been introduced for the bulk insert feature.
